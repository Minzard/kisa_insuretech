{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPFLoaEd0l08wbzNEPYNIcg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Rekt77/kisa_insuretech/blob/master/pytorch_NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jvqJU8NeZmnB",
        "colab_type": "code",
        "outputId": "5bcf3941-1cb9-4c55-8c0b-aedcc226fc50",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        }
      },
      "source": [
        "# 한글 형태소 분석기 다운로드\n",
        "!pip install konlpy"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: konlpy in /usr/local/lib/python3.6/dist-packages (0.5.2)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.6/dist-packages (from konlpy) (1.18.4)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.4.3)\n",
            "Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.6.0)\n",
            "Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (0.7.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.6/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: PySocks>=1.5.7 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (1.12.0)\n",
            "Requirement already satisfied: requests>=2.11.1 in /usr/local/lib/python3.6/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (2.9)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e5CGcfAXdTei",
        "colab_type": "code",
        "outputId": "61c180ae-c65a-4a5b-aa6c-7878c49f80a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#형태소 단위로 문장 분해\n",
        "from konlpy.tag import Kkma\n",
        "kor_nlp = Kkma()\n",
        "kor_nlp.morphs(\"운전을 배우고 있는 중\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['운전', '을', '배우', '고', '있', '는', '중']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVGZR1iFgZsb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch import optim\n",
        "from konlpy.tag import Kkma\n",
        "kor_nlp = Kkma()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6yaLi1JbVkD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 데이터 셋 저장\n",
        "# 나만의 데이터셋 만들기: 웹 사이트에서 글 크롤링\n",
        "# 운전자 커뮤니티 -> 운전자\n",
        "# 건강,헬스 커뮤니티 -> 건강\n",
        "# 등등..\n",
        "\n",
        "train_data = [[\"운전을 배우고 있는 중\",\"운전자\"],\n",
        "              [\"몸에 좋은거 챙길 나이야\",\"건강\"],\n",
        "              [\"어제 다리가 부러졌어\",\"상해\"],\n",
        "              [\"어제 사고가 났어\",\"운전자\"],\n",
        "              [\"차 사줘\",\"운전자\"],\n",
        "              [\"몸이 아픈거 같아\",\"건강\"],\n",
        "              [\"다리 아파\",\"상해\"],\n",
        "              [\"뼈가 부러졌어\",\"상해\"],\n",
        "              [\"손목이 안 좋아\",\"상해\"],\n",
        "              [\"병원 아는데 있어?\",\"건강\"],\n",
        "              [\"요즘 병원에 자주가게 되네\",\"건강\"],\n",
        "              [\"건강검진 받고 몸에 좋은거 챙겨\",\"건강\"],\n",
        "              [\"어제 운전한거 블랙박스 확인해봐\",\"운전자\"],\n",
        "              [\"손목 아프면 병원에 가야지\",\"상해\"]]\n",
        "\n",
        "test_data = [[\"운전이 하고싶어\",\"운전자\"],\n",
        "             [\"건강식 챙겨먹고 있어\",\"건강\"],\n",
        "             [\"뼈가 부러져서 금이 갔어\",\"상해\"],\n",
        "             [\"사고나면 어떻게 해야돼?\",\"운전자\"]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_UzQS4jhH3J",
        "colab_type": "code",
        "outputId": "5bf419a5-a1cc-48be-bc68-9eb67fa840fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# train_X = 문장\n",
        "# train_Y = 분류\n",
        "train_X,train_y = list(zip(*train_data))\n",
        "\n",
        "# 토큰화\n",
        "# 꼬꼬마 형태소 분석기를 이용해서 문장을 분석\n",
        "# 형태소 단위로 분해하여 train_x에 저장\n",
        "train_X = [kor_nlp.morphs(x) for x in train_X]\n",
        "\n",
        "# 단어별 인덱스를 만들것임. 모르는 단어는 unknown\n",
        "word2index={'unknown' : 0}\n",
        "\n",
        "# 문장을 추출\n",
        "for x in train_X:\n",
        "  # 형태소단위로 분해된 토큰을 추출\n",
        "    for token in x:\n",
        "      #word2index에 추가되지 않은 단어이면 단어를 추가\n",
        "        if word2index.get(token)==None:\n",
        "          #추가 할때마다 word2index의 길이를 인덱스로 반영\n",
        "            word2index[token]=len(word2index)\n",
        "\n",
        "# 클래스를 인덱스화\n",
        "# 클래스가 3개 이므로 길이 3의 딕셔너리를 생성\n",
        "class2index = {'운전자' : 0, '상해' : 1, '건강' : 1}\n",
        "print(word2index)\n",
        "print(class2index)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'unknown': 0, '운전': 1, '을': 2, '배우': 3, '고': 4, '있': 5, '는': 6, '중': 7, '몸': 8, '에': 9, '좋': 10, '은': 11, '거': 12, '챙기': 13, 'ㄹ': 14, '나이': 15, '야': 16, '어제': 17, '다리': 18, '가': 19, '부러지': 20, '었': 21, '어': 22, '사고': 23, '나': 24, '차': 25, '사': 26, '아': 27, '주': 28, '이': 29, '아프': 30, 'ㄴ': 31, '같': 32, '뼈': 33, '손목': 34, '안': 35, '좋아': 36, '병원': 37, '알': 38, '데': 39, '?': 40, '요즘': 41, '자주': 42, '가게': 43, '되': 44, '네': 45, '건강': 46, '검진': 47, '받': 48, '하': 49, '블랙': 50, '박스': 51, '확인': 52, '해보': 53, '면': 54, '야지': 55}\n",
            "{'운전자': 0, '상해': 1, '건강': 1}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2KYyZoDffspe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Bag of Words 만들기\n",
        "def make_BoW(seq,word2index):\n",
        "\n",
        "  #보유한 단어 수 크기의 0으로 초기화된 텐서 구현\n",
        "    tensor = torch.zeros(len(word2index))\n",
        "\n",
        "    #seq는 형태소 문장\n",
        "    #w는 나누어진 형태소\n",
        "    for w in seq:\n",
        "      # word2index로 부터 w의 인덱스를 구함\n",
        "        index = word2index.get(w)\n",
        "\n",
        "        # 인덱스가 있을 경우\n",
        "        if index!=None:\n",
        "          # 해당 인덱스의 값을 1로 만들어줌\n",
        "            tensor[index]+=1.\n",
        "\n",
        "        # 인덱스가 없는경우\n",
        "        else:\n",
        "          # unknown의 값이 인덱스가 되고\n",
        "          # 해당 인덱스의 값을 1로 만들어줌\n",
        "            index = word2index['unknown']\n",
        "            tensor[index]+=1.\n",
        "    \n",
        "    return tensor\n",
        "\n",
        "# ['운전', '을', '배우', '고', '있', '는', '중']의 인덱스가 0,1,2,3,4,5,6 이라면\n",
        "# 0~6번째 요소가 1로 채워진 텐서가 만들어짐\n",
        "\n",
        "train_X = torch.cat([Variable(make_BoW(x,word2index)).view(1,-1) for x in train_X])\n",
        "train_y = torch.cat([Variable(torch.LongTensor([class2index[y]])) for y in train_y])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vZtXfHsgqEOK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.cat([Variable(make_BoW(x,word2index)).view(1,-1) for x in train_X])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xp0WZ7aOsm61",
        "colab_type": "text"
      },
      "source": [
        "# Word2Vec\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fK5LJpxRfwnI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# BoW classifier 만들기\n",
        "class BoWClassifier(nn.Module):\n",
        "    def __init__(self,vocab_size,output_size):\n",
        "        super(BoWClassifier,self).__init__()\n",
        "        \n",
        "        # 뉴런간 선형결합\n",
        "        # vocab을 아웃풋에 연결하여 연산\n",
        "        self.linear = nn.Linear(vocab_size,output_size)\n",
        "    \n",
        "    def forward(self,inputs):\n",
        "        return self.linear(inputs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZDmTSJhfzGl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 학습\n",
        "epochs = 1000\n",
        "LR = 0.1\n",
        "\n",
        "# 인풋 크기는 word2index의 길이\n",
        "# 아웃풋은 3(클래스가 3개이기 때문)\n",
        "model = BoWClassifier(len(word2index),3)\n",
        "\n",
        "# cost함수 선언\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# 경사하강법으로 학습\n",
        "optimizer = optim.SGD(model.parameters(),lr=LR)\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    model.zero_grad()\n",
        "    hypothesis = model(train_X)\n",
        "    loss = loss_function(hypothesis,train_y)\n",
        "    if epoch % 10 == 0:\n",
        "        print(loss.item())\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nmtAaBxmf2WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 테스트\n",
        "index2class = {v:k for k,v in class2index.items()}\n",
        "\n",
        "for test in test_data:\n",
        "\n",
        "  # 테스트 데이터 불러오기\n",
        "    X = kor_nlp.morphs(test[0])\n",
        "    X = Variable(make_BoW(X,word2index)).view(1,-1)\n",
        "    \n",
        "    pred = model(X)\n",
        "    \n",
        "    # 3가지 클래스 분류 중에 가장 높은것 추출\n",
        "    pred = pred.max(1)[1].item()\n",
        "    print(\"Input : %s\" % test[0])\n",
        "    print(\"Prediction : %s\" % index2class[pred])\n",
        "    print(\"Truth : %s\" % test[1])"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}